{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out first CNN on EEG data with labels\n",
    "\n",
    "## Pre-processing\n",
    "+ Import data.\n",
    "+ Apply filters (bandpass).\n",
    "+ Detect potential bad channels and replace them by interpolation.\n",
    "+ Detect potential bad epochs and remove them.\n",
    "\n",
    "## Train CNN network\n",
    "+ Define network architecture\n",
    "+ Split data\n",
    "+ Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "#%matplotlib inline\n",
    "\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"C:\\\\OneDrive - Netherlands eScience Center\\\\Project_ePodium\\\\\"\n",
    "PATH_CODE = ROOT + \"EEG_explorer\\\\\"\n",
    "PATH_DATA = ROOT + \"Data\\\\\"\n",
    "PATH_OUTPUT = ROOT + \"Data\\\\processed\\\\\"\n",
    "PATH_METADATA = ROOT + \"Data\\\\metadata\\\\\"\n",
    "file_labels = \"metadata.xlsx\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, PATH_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed dataset\n",
    "+ See notebook for preprocessing: Exploring_EEG_data_04_prepare_data_for_ML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected.npy\"\n",
    "signal_collection = np.load(filename)\n",
    "\n",
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected_labels.npy\"\n",
    "label_collection = np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data\n",
    "The entire dataset is split into:\n",
    "+ training data (here: about 70%) which is used to train a model.\n",
    "+ validation data, used to monitor the model progress and avoid overfitting.\n",
    "+ testing data, meant for final check on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(signal_collection, label_collection, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 28237\n",
      "Validation set size: 4983\n",
      "Test set size: 5863\n"
     ]
    }
   ],
   "source": [
    "print('Train set size:', X_train.shape[0])\n",
    "print('Validation set size:', X_val.shape[0])\n",
    "print('Test set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to 1-hot encoding for labels\n",
    "+ We have six categories or classes. Those are best represented by a so called 1-hot encoding. This means nothing else than simply a binary 0-or-1 for every class.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_transform = LabelBinarizer()\n",
    "\n",
    "y_train_binary = label_transform.fit_transform(y_train.astype(int))\n",
    "y_val_binary = label_transform.fit_transform(y_val.astype(int))\n",
    "y_test_binary = label_transform.fit_transform(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binary[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   6,  13,  26,  66, 132])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show found labels:\n",
    "label_transform.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution accross the 6 label categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.488437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.038885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.061515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.038141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.059815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frequency\n",
       "3     0.313206\n",
       "6     0.488437\n",
       "13    0.038885\n",
       "26    0.061515\n",
       "66    0.038141\n",
       "132   0.059815"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label_transform.classes_)\n",
    "frequencies = y_train_binary.mean(axis=0)\n",
    "frequencies_df = pd.DataFrame(frequencies, index=labels, columns=['frequency'])\n",
    "frequencies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "We have more data on group 2 than on group 1. And far more data for stimuli 3 than for stimuli 13 and 66 (not surprising). \n",
    "\n",
    "### Needs some thinking on how to balance the data set !\n",
    "e.g. by frequency dependend selection rule, or by defining a suitied special loss function...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 14:02:46.179984 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 14:02:46.211227 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 14:02:46.258124 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0722 14:02:46.289368 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0722 14:02:46.320579 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0722 14:02:46.367473 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0722 14:02:47.445311 12396 deprecation.py:506] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0722 14:02:47.492175 12396 deprecation_wrapper.py:119] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mcfly\n",
    "\n",
    "num_classes = y_train_binary.shape[1]\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0003361608602243409, 'regularization_rate': 0.08420322758301782, 'filters': [84, 18, 15, 93, 60, 27, 90, 65], 'lstm_dims': [37, 54]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 501, 84)       336       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 501, 84)       336       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 501, 84)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 501, 18)       4554      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 501, 18)       72        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 501, 18)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 501, 15)       825       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 501, 15)       60        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30, 501, 15)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 501, 93)       4278      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 501, 93)       372       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 501, 93)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 501, 60)       16800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 501, 60)       240       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 501, 60)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 501, 27)       4887      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 501, 27)       108       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 501, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 501, 90)       7380      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 501, 90)       360       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 501, 90)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 501, 65)       17615     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 501, 65)       260       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 501, 65)       0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 30, 32565)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 37)            4825244   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 54)            19872     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 54)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 6)             330       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 4,905,933\n",
      "Trainable params: 4,904,027\n",
      "Non-trainable params: 1,906\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.02018269111060801, 'regularization_rate': 0.002334813332915235, 'filters': [80, 91, 95, 35, 16, 50, 67], 'lstm_dims': [15]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_10 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 501, 80)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 501, 80)       320       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 501, 80)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 501, 91)       21931     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 501, 91)       364       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 501, 91)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 501, 95)       26030     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 501, 95)       380       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 30, 501, 95)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 501, 35)       10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 501, 35)       140       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 501, 35)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 501, 16)       1696      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 501, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 501, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 501, 50)       2450      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 501, 50)       200       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30, 501, 50)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 501, 67)       10117     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 501, 67)       268       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 30, 501, 67)       0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 30, 33567)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 15)            2014980   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 15)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 6)             96        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,091,370\n",
      "Trainable params: 2,089,500\n",
      "Non-trainable params: 1,870\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.00022741441440156444, 'regularization_rate': 0.0019189096850250862, 'filters': [11, 21, 27, 57, 53, 40, 35], 'lstm_dims': [14, 76]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_18 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 501, 11)       44        \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 501, 11)       44        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 501, 11)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 501, 21)       714       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 501, 21)       84        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 501, 21)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 501, 27)       1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 501, 27)       108       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 501, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 501, 57)       4674      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 501, 57)       228       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 30, 501, 57)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 501, 53)       9116      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 501, 53)       212       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 30, 501, 53)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 501, 40)       6400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 501, 40)       160       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 30, 501, 40)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 501, 35)       4235      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 501, 35)       140       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 30, 501, 35)       0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 30, 17535)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 14)            982800    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 76)            27664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 76)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 6)             462       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,040,817\n",
      "Trainable params: 1,039,327\n",
      "Non-trainable params: 1,490\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.012457145861743539, 'regularization_rate': 0.00012682358552716384, 'filters': [89, 87, 49, 39, 47, 35, 89], 'lstm_dims': [37, 53, 88, 19, 72]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_26 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 501, 89)       356       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 501, 89)       356       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 501, 89)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 501, 87)       23316     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 501, 87)       348       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 30, 501, 87)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 501, 49)       12838     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 501, 49)       196       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 30, 501, 49)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 501, 39)       5772      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 501, 39)       156       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30, 501, 39)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 501, 47)       5546      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 501, 47)       188       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 30, 501, 47)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 501, 35)       4970      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 501, 35)       140       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 30, 501, 35)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 501, 89)       9434      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 501, 89)       356       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30, 501, 89)       0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 30, 44589)         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 37)            6604796   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 53)            19292     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 88)            49984     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30, 19)            8208      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 30, 72)            26496     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 72)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 6)             438       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 6,775,190\n",
      "Trainable params: 6,773,318\n",
      "Non-trainable params: 1,872\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.008592389575456024, 'regularization_rate': 0.012195862535583357, 'filters': array([45, 21, 56, 24, 10, 25]), 'fc_hidden_nodes': 511}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_34 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 45)            67680     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 45)            180       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 30, 45)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 21)            2856      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 30, 21)            84        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 30, 21)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 30, 56)            3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 30, 56)            224       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 30, 56)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 24)            4056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 30, 24)            96        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 24)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30, 10)            730       \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 30, 10)            40        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 30, 25)            775       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 30, 25)            100       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 30, 25)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 511)               383761    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 511)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 3072      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 469,266\n",
      "Trainable params: 467,890\n",
      "Non-trainable params: 1,376\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 5\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0009333418066746328, 'regularization_rate': 0.0028692206913423857, 'filters': [80, 94, 37, 85, 33, 82, 89], 'lstm_dims': [71, 51]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_42 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 501, 80)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 30, 501, 80)       320       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 30, 501, 80)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 501, 94)       22654     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 30, 501, 94)       376       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 30, 501, 94)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 501, 37)       10471     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 30, 501, 37)       148       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30, 501, 37)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 501, 85)       9520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 30, 501, 85)       340       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 30, 501, 85)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 501, 33)       8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 30, 501, 33)       132       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 30, 501, 33)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 501, 82)       8200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 30, 501, 82)       328       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 30, 501, 82)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 30, 501, 89)       21983     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 30, 501, 89)       356       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 30, 501, 89)       0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 30, 44589)         0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 30, 71)            12683724  \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 30, 51)            25092     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 51)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 6)             312       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 12,794,728\n",
      "Trainable params: 12,792,726\n",
      "Non-trainable params: 2,002\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 6\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.036049600597093626, 'regularization_rate': 0.07340447191427084, 'filters': array([60, 14, 60, 53, 68, 36, 79, 61, 76, 56]), 'fc_hidden_nodes': 91}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_50 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 30, 60)            90240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 30, 60)            240       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 30, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 30, 14)            2534      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 30, 14)            56        \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 30, 14)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 30, 60)            2580      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 30, 60)            240       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 30, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30, 53)            9593      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 30, 53)            212       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 30, 53)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 30, 68)            10880     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 30, 68)            272       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 30, 68)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 30, 36)            7380      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 30, 36)            144       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 30, 36)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 30, 79)            8611      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 30, 79)            316       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 30, 79)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 30, 61)            14518     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 30, 61)            244       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 30, 61)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 30, 76)            13984     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 30, 76)            304       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 30, 76)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 30, 56)            12824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 30, 56)            224       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 30, 56)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1680)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 91)                152971    \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 552       \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 330,947\n",
      "Trainable params: 328,807\n",
      "Non-trainable params: 2,140\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 7\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.002629638129838506, 'regularization_rate': 0.051830205622591996, 'filters': array([30, 18, 69, 55, 27, 77, 96]), 'fc_hidden_nodes': 236}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_62 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 30, 30)            45120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 30, 30)            120       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 30, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 30, 18)            1638      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 30, 18)            72        \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 30, 18)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 30, 69)            3795      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 30, 69)            276       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 30, 69)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 30, 55)            11440     \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 30, 55)            220       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 30, 55)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 30, 27)            4482      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 30, 27)            108       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 30, 27)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 30, 77)            6314      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 30, 77)            308       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 30, 77)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 30, 96)            22272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 30, 96)            384       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 30, 96)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 236)               679916    \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 236)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 1422      \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 779,915\n",
      "Trainable params: 778,157\n",
      "Non-trainable params: 1,758\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 14:09:26.241415 12396 deprecation.py:323] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 300 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "240/300 [=======================>......] - ETA: 40s - loss: 39.9084 - acc: 0.3667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f7b4b1d65791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                            \u001b[0msubset_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                                                            outputfile=outputfile)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Details of the training process were stored in '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\mcfly\\find_architecture.py\u001b[0m in \u001b[0;36mtrain_models_on_samples\u001b[1;34m(X_train, y_train, X_val, y_val, models, nr_epochs, subset_size, verbose, outputfile, model_path, early_stopping, batch_size, metric)\u001b[0m\n\u001b[0;32m    111\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(PATH_OUTPUT, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = mcfly.find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models, nr_epochs=5,\n",
    "                                                                           subset_size=300,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
