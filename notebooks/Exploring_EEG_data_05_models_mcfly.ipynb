{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out first CNN on EEG data with labels\n",
    "\n",
    "## Pre-processing\n",
    "+ Import data.\n",
    "+ Apply filters (bandpass).\n",
    "+ Detect potential bad channels and replace them by interpolation.\n",
    "+ Detect potential bad epochs and remove them.\n",
    "\n",
    "## Train CNN network\n",
    "+ Define network architecture\n",
    "+ Split data\n",
    "+ Train model\n",
    "\n",
    "### Use mcfly for some first model testing: https://github.com/NLeSC/mcfly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "#%matplotlib inline\n",
    "\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"C:\\\\OneDrive - Netherlands eScience Center\\\\Project_ePodium\\\\\"\n",
    "PATH_CODE = ROOT + \"EEG_explorer\\\\\"\n",
    "PATH_DATA = ROOT + \"Data\\\\\"\n",
    "PATH_OUTPUT = ROOT + \"Data\\\\processed\\\\\"\n",
    "PATH_METADATA = ROOT + \"Data\\\\metadata\\\\\"\n",
    "file_labels = \"metadata.xlsx\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, PATH_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed dataset\n",
    "+ See notebook for preprocessing: Exploring_EEG_data_04_prepare_data_for_ML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected.npy\"\n",
    "signal_collection = np.load(filename)\n",
    "\n",
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected_labels.npy\"\n",
    "label_collection = np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data\n",
    "The entire dataset is split into:\n",
    "+ training data (here: about 70%) which is used to train a model.\n",
    "+ validation data, used to monitor the model progress and avoid overfitting.\n",
    "+ testing data, meant for final check on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(signal_collection, label_collection, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 28237\n",
      "Validation set size: 4983\n",
      "Test set size: 5863\n"
     ]
    }
   ],
   "source": [
    "print('Train set size:', X_train.shape[0])\n",
    "print('Validation set size:', X_val.shape[0])\n",
    "print('Test set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to 1-hot encoding for labels\n",
    "+ We have six categories or classes. Those are best represented by a so called 1-hot encoding. This means nothing else than simply a binary 0-or-1 for every class.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_transform = LabelBinarizer()\n",
    "\n",
    "y_train_binary = label_transform.fit_transform(y_train.astype(int))\n",
    "y_val_binary = label_transform.fit_transform(y_val.astype(int))\n",
    "y_test_binary = label_transform.fit_transform(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binary[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   6,  13,  26,  66, 132])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show found labels:\n",
    "label_transform.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution accross the 6 label categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.488437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.038885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.061515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.038141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.059815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frequency\n",
       "3     0.313206\n",
       "6     0.488437\n",
       "13    0.038885\n",
       "26    0.061515\n",
       "66    0.038141\n",
       "132   0.059815"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label_transform.classes_)\n",
    "frequencies = y_train_binary.mean(axis=0)\n",
    "frequencies_df = pd.DataFrame(frequencies, index=labels, columns=['frequency'])\n",
    "frequencies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "We have more data on group 2 than on group 1. And far more data for stimuli 3 than for stimuli 13 and 66 (not surprising). \n",
    "\n",
    "--> post on balancing datasets: https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758\n",
    "\n",
    "### Needs some thinking on how to balance the data set !\n",
    "e.g. by frequency dependend selection rule, or by defining a suitied special loss function...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import mcfly\n",
    "\n",
    "num_classes = y_train_binary.shape[1]\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.08025860382407397, 'regularization_rate': 0.0047806729439940415, 'filters': array([64]), 'fc_hidden_nodes': 509}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 64)            96256     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 509)               977789    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 509)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3060      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,079,389\n",
      "Trainable params: 1,078,247\n",
      "Non-trainable params: 1,142\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0013802557466330953, 'regularization_rate': 0.00859915782317467, 'filters': array([36, 95]), 'fc_hidden_nodes': 315}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 36)            54144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 36)            144       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 36)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 30, 95)            10355     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 95)            380       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 95)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2850)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 315)               898065    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 315)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1896      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 967,012\n",
      "Trainable params: 965,736\n",
      "Non-trainable params: 1,276\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.008166179639032047, 'regularization_rate': 0.04463687712501541, 'filters': [95, 92, 91, 93, 60, 18, 75, 49, 25], 'lstm_dims': [42]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 501, 95)       380       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 501, 95)       380       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 501, 95)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 501, 92)       26312     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 501, 92)       368       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 501, 92)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 501, 91)       25207     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 501, 91)       364       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 501, 91)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 501, 93)       25482     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 501, 93)       372       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 501, 93)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 501, 60)       16800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 501, 60)       240       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 30, 501, 60)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 501, 18)       3258      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 501, 18)       72        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 501, 18)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 501, 75)       4125      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 501, 75)       300       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 501, 75)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 501, 49)       11074     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 501, 49)       196       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30, 501, 49)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 501, 25)       3700      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 501, 25)       100       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 30, 501, 25)       0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 30, 12525)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 42)            2111424   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 42)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 6)             258       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,232,416\n",
      "Trainable params: 2,230,218\n",
      "Non-trainable params: 2,198\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0016160808630266655, 'regularization_rate': 0.0037947474090358453, 'filters': [62, 11], 'lstm_dims': [55]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_18 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 501, 62)       248       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 501, 62)       248       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 501, 62)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 501, 11)       2057      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 501, 11)       44        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 501, 11)       0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 30, 5511)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 55)            1224740   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 55)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 6)             336       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,229,677\n",
      "Trainable params: 1,228,529\n",
      "Non-trainable params: 1,148\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.06536170068583848, 'regularization_rate': 0.00023986864024244713, 'filters': array([37]), 'fc_hidden_nodes': 1045}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_21 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 37)            55648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 37)            148       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 30, 37)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1110)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1045)              1160995   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1045)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 6276      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,225,095\n",
      "Trainable params: 1,224,007\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 5\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0003331670778308405, 'regularization_rate': 0.017074265219543836, 'filters': array([18, 54, 28, 29, 31]), 'fc_hidden_nodes': 698}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_24 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30, 18)            27072     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 18)            72        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 30, 18)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 30, 54)            2970      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 54)            216       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 30, 54)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 30, 28)            4564      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 28)            112       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 28)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 30, 29)            2465      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 29)            116       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 30, 29)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 30, 31)            2728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 31)            124       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 30, 31)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 930)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 698)               649838    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 698)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 4194      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 696,499\n",
      "Trainable params: 695,165\n",
      "Non-trainable params: 1,334\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 6\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.06916869676107712, 'regularization_rate': 0.00806225703992415, 'filters': array([58, 31]), 'fc_hidden_nodes': 1766}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_31 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30, 58)            87232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 58)            232       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 30, 58)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 30, 31)            5425      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 31)            124       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30, 31)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 930)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1766)              1644146   \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1766)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 10602     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,749,789\n",
      "Trainable params: 1,748,597\n",
      "Non-trainable params: 1,192\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 7\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.031225307009075057, 'regularization_rate': 0.031797187434842084, 'filters': [49, 66, 68, 31, 52, 61, 87, 60, 56, 53], 'lstm_dims': [24, 62, 96, 61]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_35 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 501, 49)       196       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 30, 501, 49)       196       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 30, 501, 49)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 501, 66)       9768      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 30, 501, 66)       264       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 30, 501, 66)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 501, 68)       13532     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 30, 501, 68)       272       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 501, 68)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 501, 31)       6355      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 30, 501, 31)       124       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 501, 31)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 501, 52)       4888      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 30, 501, 52)       208       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 30, 501, 52)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 501, 61)       9577      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 30, 501, 61)       244       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 30, 501, 61)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 501, 87)       16008     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 30, 501, 87)       348       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 30, 501, 87)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 501, 60)       15720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 30, 501, 60)       240       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 30, 501, 60)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 501, 56)       10136     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 30, 501, 56)       224       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 30, 501, 56)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 501, 53)       8957      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 30, 501, 53)       212       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30, 501, 53)       0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 30, 26553)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 24)            2551488   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 62)            21576     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 96)            61056     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 61)            38552     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 61)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 6)             372       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,772,517\n",
      "Trainable params: 2,770,349\n",
      "Non-trainable params: 2,168\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 14:09:26.241415 12396 deprecation.py:323] From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 300 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "240/300 [=======================>......] - ETA: 40s - loss: 39.9084 - acc: 0.3667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f7b4b1d65791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                            \u001b[0msubset_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                                                            outputfile=outputfile)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Details of the training process were stored in '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\mcfly\\find_architecture.py\u001b[0m in \u001b[0;36mtrain_models_on_samples\u001b[1;34m(X_train, y_train, X_val, y_val, models, nr_epochs, subset_size, verbose, outputfile, model_path, early_stopping, batch_size, metric)\u001b[0m\n\u001b[0;32m    111\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(PATH_OUTPUT, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = mcfly.find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models, nr_epochs=5,\n",
    "                                                                           subset_size=300,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
